{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59567414",
   "metadata": {},
   "source": [
    "# Project Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaca03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor        \n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pd.set_option('display.max_columns', None)\n",
    "import re\n",
    "import nltk\n",
    "from googletrans import Translator\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from textblob import TextBlob\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44da69b5",
   "metadata": {},
   "source": [
    "### Data Preprocessing - Krishna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c945ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>NAME</th>\n",
       "      <th>host id</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>host name</th>\n",
       "      <th>neighbourhood group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>country</th>\n",
       "      <th>country code</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>room type</th>\n",
       "      <th>Construction year</th>\n",
       "      <th>price</th>\n",
       "      <th>service fee</th>\n",
       "      <th>minimum nights</th>\n",
       "      <th>number of reviews</th>\n",
       "      <th>last review</th>\n",
       "      <th>reviews per month</th>\n",
       "      <th>review rate number</th>\n",
       "      <th>calculated host listings count</th>\n",
       "      <th>availability 365</th>\n",
       "      <th>house_rules</th>\n",
       "      <th>license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001254</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>80014485718</td>\n",
       "      <td>unconfirmed</td>\n",
       "      <td>Madaline</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>strict</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>$966</td>\n",
       "      <td>$193</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10/19/2021</td>\n",
       "      <td>0.21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>Clean up and treat the home the way you'd like...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002102</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>52335172823</td>\n",
       "      <td>verified</td>\n",
       "      <td>Jenna</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>$142</td>\n",
       "      <td>$28</td>\n",
       "      <td>30.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5/21/2022</td>\n",
       "      <td>0.38</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>Pet friendly but please confirm with me if the...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002403</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>78829239556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elise</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>True</td>\n",
       "      <td>flexible</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>$620</td>\n",
       "      <td>$124</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>I encourage you to use my kitchen, cooking and...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1002755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85098326012</td>\n",
       "      <td>unconfirmed</td>\n",
       "      <td>Garry</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>True</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>$368</td>\n",
       "      <td>$74</td>\n",
       "      <td>30.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>7/5/2019</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1003689</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>92037596077</td>\n",
       "      <td>verified</td>\n",
       "      <td>Lyndon</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>$204</td>\n",
       "      <td>$41</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11/19/2018</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>Please no smoking in the house, porch or on th...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              NAME      host id  \\\n",
       "0  1001254                Clean & quiet apt home by the park  80014485718   \n",
       "1  1002102                             Skylit Midtown Castle  52335172823   \n",
       "2  1002403               THE VILLAGE OF HARLEM....NEW YORK !  78829239556   \n",
       "3  1002755                                               NaN  85098326012   \n",
       "4  1003689  Entire Apt: Spacious Studio/Loft by central park  92037596077   \n",
       "\n",
       "  host_identity_verified host name neighbourhood group neighbourhood  \\\n",
       "0            unconfirmed  Madaline            Brooklyn    Kensington   \n",
       "1               verified     Jenna           Manhattan       Midtown   \n",
       "2                    NaN     Elise           Manhattan        Harlem   \n",
       "3            unconfirmed     Garry            Brooklyn  Clinton Hill   \n",
       "4               verified    Lyndon           Manhattan   East Harlem   \n",
       "\n",
       "        lat      long        country country code instant_bookable  \\\n",
       "0  40.64749 -73.97237  United States           US            False   \n",
       "1  40.75362 -73.98377  United States           US            False   \n",
       "2  40.80902 -73.94190  United States           US             True   \n",
       "3  40.68514 -73.95976  United States           US             True   \n",
       "4  40.79851 -73.94399  United States           US            False   \n",
       "\n",
       "  cancellation_policy        room type  Construction year  price service fee  \\\n",
       "0              strict     Private room             2020.0  $966        $193    \n",
       "1            moderate  Entire home/apt             2007.0  $142         $28    \n",
       "2            flexible     Private room             2005.0  $620        $124    \n",
       "3            moderate  Entire home/apt             2005.0  $368         $74    \n",
       "4            moderate  Entire home/apt             2009.0  $204         $41    \n",
       "\n",
       "   minimum nights  number of reviews last review  reviews per month  \\\n",
       "0            10.0                9.0  10/19/2021               0.21   \n",
       "1            30.0               45.0   5/21/2022               0.38   \n",
       "2             3.0                0.0         NaN                NaN   \n",
       "3            30.0              270.0    7/5/2019               4.64   \n",
       "4            10.0                9.0  11/19/2018               0.10   \n",
       "\n",
       "   review rate number  calculated host listings count  availability 365  \\\n",
       "0                 4.0                             6.0             286.0   \n",
       "1                 4.0                             2.0             228.0   \n",
       "2                 5.0                             1.0             352.0   \n",
       "3                 4.0                             1.0             322.0   \n",
       "4                 3.0                             1.0             289.0   \n",
       "\n",
       "                                         house_rules license  \n",
       "0  Clean up and treat the home the way you'd like...     NaN  \n",
       "1  Pet friendly but please confirm with me if the...     NaN  \n",
       "2  I encourage you to use my kitchen, cooking and...     NaN  \n",
       "3                                                NaN     NaN  \n",
       "4  Please no smoking in the house, porch or on th...     NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "data = pd.read_csv('Airbnb_Open_Data.csv',low_memory=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a62bb36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102599, 26)\n",
      "(10260, 26)\n"
     ]
    }
   ],
   "source": [
    "#Harshitha\n",
    "#Delete-reducing the size of the dataset for testing\n",
    "\n",
    "print(data.shape)\n",
    "#Number of rows to drop\n",
    "droprow=int(len(data)*90/100)\n",
    "#Dropping the rows\n",
    "data=data.iloc[:-droprow]\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78cc6b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting features from \"house rules\"\n",
    "\n",
    "data['house_rules']=data['house_rules'].fillna('')\n",
    "data['house_rules']=data['house_rules'].astype(str)\n",
    "\n",
    "\n",
    "#Translating chinese reviews into english\n",
    "def translatechinese(text):   \n",
    "    \n",
    "    #Creating a function that checks if there are any Chinese house rules\n",
    "    def containschinese(text):\n",
    "        if text is None or text.strip=='':\n",
    "            return False\n",
    "        else:\n",
    "            match = bool(re.search('[\\u4e00-\\u9fff]', text))\n",
    "            return match\n",
    "    \n",
    "    if containschinese(text):\n",
    "        translator=Translator()\n",
    "        translated= translator.translate(text,src='zh-cn', dest='en')\n",
    "        return translated.text\n",
    "    \n",
    "    else:\n",
    "        return text\n",
    "    \n",
    "    \n",
    "\n",
    "data[\"translated\"]=data['house_rules'].apply(lambda x: translatechinese(x))\n",
    "text_all=data[\"translated\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b223848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning up translated text in house rules\n",
    "\n",
    "import wordninja\n",
    "\n",
    "#Converting text into lower case\n",
    "text=' '.join(list(map(str.lower,text_all)))\n",
    "\n",
    "#Removing tags\n",
    "text=re.sub('<.*>.','',text)\n",
    "\n",
    "#Removing punctuation\n",
    "text=re.sub(r'[^\\w\\s]','',text)\n",
    "\n",
    "#Removing numbers\n",
    "text=re.sub(r'\\d+','',text)\n",
    "\n",
    "text=set(text.split(' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "058791db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete this code\n",
    "\n",
    "df=pd.DataFrame(set(text))\n",
    "df.to_excel(\"dataframe.xlsx\",sheet_name=\"firstsheet\",index=False)\n",
    "\n",
    "text=' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07b99034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running spell check on the words \n",
    "\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "spell=SpellChecker()\n",
    "text_list=[]\n",
    "for word in re.split(r'\\s+',text.strip()):\n",
    "\n",
    "    if spell.correction(word)==None:\n",
    "        if wordninja.split(word):\n",
    "\n",
    "            text_list.append(' '.join(wordninja.split(word)))\n",
    "    else:\n",
    "\n",
    "        text_list.append(word)          \n",
    "        text=' '.join(text_list)\n",
    "        \n",
    "        \n",
    "\n",
    "#Removing stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "text=[word for word in text.split(' ') if word not in stop_words]\n",
    "text=' '.join(text)\n",
    "\n",
    "\n",
    "#Can delete this portion of the code\n",
    "df=pd.DataFrame(text.split(' '))\n",
    "df.to_excel(\"dataframewords.xlsx\",sheet_name=\"firstsheet\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4f0fc6",
   "metadata": {},
   "source": [
    "#Stemming - not producing good results\n",
    "\n",
    "\n",
    "stemmer=SnowballStemmer('english')\n",
    "text=([stemmer.stem(word) for word in text.split(' ')])\n",
    "\n",
    "df=pd.DataFrame(text)\n",
    "df.to_excel(\"dataframewordsafterstem.xlsx\",sheet_name=\"firstsheet\",index=False)\n",
    "\n",
    "text=' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eaf6a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4079\n"
     ]
    }
   ],
   "source": [
    "finaltext= set(text.split(' '))\n",
    "print(len(finaltext))\n",
    "\n",
    "#Printing features to excel(Can delete)\n",
    "df=pd.DataFrame(finaltext)\n",
    "df.to_excel(\"finaltext.xlsx\",sheet_name=\"firstsheet\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e95c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Can delete this portion of the code\n",
    "#Tokenizing the words-Using sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer=CountVectorizer(vocabulary=finaltext)\n",
    "\n",
    "X=vectorizer.transform(data[\"translated\"])\n",
    "bow_array=X.toarray()\n",
    "feature_names=vectorizer.get_feature_names_out()\n",
    "\n",
    "#Creating an dataframe with the new features created\n",
    "extracted_features=pd.DataFrame(bow_array,columns=feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a387c1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>room_type</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>review_rate_number</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>translated</th>\n",
       "      <th>days_since_last_review</th>\n",
       "      <th>years_since_construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unconfirmed</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>False</td>\n",
       "      <td>strict</td>\n",
       "      <td>Private room</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>Clean up and treat the home the way you'd like...</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>verified</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>False</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>30.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>Pet friendly but please confirm with me if the...</td>\n",
       "      <td>924.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unconfirmed</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>True</td>\n",
       "      <td>flexible</td>\n",
       "      <td>Private room</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>I encourage you to use my kitchen, cooking and...</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unconfirmed</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>True</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>30.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td></td>\n",
       "      <td>1975.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>verified</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>False</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>Please no smoking in the house, porch or on th...</td>\n",
       "      <td>2203.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  host_identity_verified neighbourhood_group neighbourhood instant_bookable  \\\n",
       "0            unconfirmed            Brooklyn    Kensington            False   \n",
       "1               verified           Manhattan       Midtown            False   \n",
       "2            unconfirmed           Manhattan        Harlem             True   \n",
       "3            unconfirmed            Brooklyn  Clinton Hill             True   \n",
       "4               verified           Manhattan   East Harlem            False   \n",
       "\n",
       "  cancellation_policy        room_type  minimum_nights  number_of_reviews  \\\n",
       "0              strict     Private room            10.0                9.0   \n",
       "1            moderate  Entire home/apt            30.0               45.0   \n",
       "2            flexible     Private room             3.0                0.0   \n",
       "3            moderate  Entire home/apt            30.0              270.0   \n",
       "4            moderate  Entire home/apt            10.0                9.0   \n",
       "\n",
       "   reviews_per_month  review_rate_number  calculated_host_listings_count  \\\n",
       "0               0.21                 4.0                             6.0   \n",
       "1               0.38                 4.0                             2.0   \n",
       "2               2.51                 5.0                             1.0   \n",
       "3               4.64                 4.0                             1.0   \n",
       "4               0.10                 3.0                             1.0   \n",
       "\n",
       "   availability_365                                         translated  \\\n",
       "0             286.0  Clean up and treat the home the way you'd like...   \n",
       "1             228.0  Pet friendly but please confirm with me if the...   \n",
       "2             352.0  I encourage you to use my kitchen, cooking and...   \n",
       "3             322.0                                                      \n",
       "4             289.0  Please no smoking in the house, porch or on th...   \n",
       "\n",
       "   days_since_last_review  years_since_construction  \n",
       "0                  1138.0                       4.0  \n",
       "1                   924.0                      17.0  \n",
       "2                  9999.0                      19.0  \n",
       "3                  1975.0                      19.0  \n",
       "4                  2203.0                      15.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize Column Names\n",
    "data.columns = [col.lower().replace(' ', '_') if len(col.split()) >= 2 else col.lower() for col in data.columns]\n",
    "\n",
    "# Drop Irrelevant Columns\n",
    "irrelevant_columns = ['id', 'name', 'host_id', 'host_name', 'license', 'house_rules', \n",
    "                      'country', 'country_code', 'lat', 'long', 'service_fee']\n",
    "data_cleaned = data.drop(columns=irrelevant_columns)\n",
    "\n",
    "# Clean Price and Service Fee Data\n",
    "data_cleaned['price'] = data_cleaned['price'].str.replace('[^\\d.]', '', regex=True).astype(float)\n",
    "\n",
    "# Store Price seperately\n",
    "response = data_cleaned['price']\n",
    "data_cleaned = data_cleaned.drop(['price'], axis=1)\n",
    "response = response.interpolate(method='linear')\n",
    "\n",
    "# Derive days_since_last_review from last_review \n",
    "data_cleaned['last_review'] = pd.to_datetime(data_cleaned['last_review'], errors='coerce')\n",
    "reference_date = datetime.now()\n",
    "data_cleaned['days_since_last_review'] = (reference_date - data_cleaned['last_review']).dt.days\n",
    "data_cleaned['days_since_last_review'].fillna(9999, inplace=True)\n",
    "data_cleaned.drop(columns=['last_review'], inplace=True)\n",
    "\n",
    "# Derive years_since_construction from construction_year\n",
    "current_year = datetime.now().year\n",
    "data_cleaned['years_since_construction'] = current_year - data_cleaned['construction_year']\n",
    "data_cleaned.drop(columns=['construction_year'], inplace=True)\n",
    "\n",
    "# Clean neighbourhood_group data\n",
    "correct_mapping = {'brookln': 'Brooklyn','manhatan': 'Manhattan'}\n",
    "data_cleaned['neighbourhood_group'] = data_cleaned['neighbourhood_group'].replace(correct_mapping)\n",
    "\n",
    "# Impute Numerical Missing Data Using Linear Interpolation\n",
    "numeric_columns = data_cleaned.select_dtypes(include=['float64']).columns\n",
    "data_cleaned[numeric_columns] = data_cleaned[numeric_columns].apply(lambda col: col.interpolate(method='linear'))\n",
    "\n",
    "# # Scale Numeric Data\n",
    "# scaler = StandardScaler()\n",
    "# data_cleaned[numeric_columns] = scaler.fit_transform(data_cleaned[numeric_columns])\n",
    "# data_cleaned[numeric_columns] = scaler.transform(data_cleaned[numeric_columns])\n",
    "\n",
    "# Impute Categorical Missing Data Using Mode Imputation\n",
    "categorical_columns = data_cleaned.select_dtypes(include=['object']).columns\n",
    "data_cleaned[categorical_columns] = data_cleaned[categorical_columns].astype('category')\n",
    "data_cleaned[categorical_columns] = data_cleaned[categorical_columns].apply(lambda col: col.fillna(col.mode()[0]))\n",
    "\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55b5940c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_identity_verified            category\n",
       "neighbourhood_group               category\n",
       "neighbourhood                     category\n",
       "instant_bookable                  category\n",
       "cancellation_policy               category\n",
       "room_type                         category\n",
       "minimum_nights                     float64\n",
       "number_of_reviews                  float64\n",
       "reviews_per_month                  float64\n",
       "review_rate_number                 float64\n",
       "calculated_host_listings_count     float64\n",
       "availability_365                   float64\n",
       "translated                        category\n",
       "days_since_last_review             float64\n",
       "years_since_construction           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b6cde0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10260, 4093)\n"
     ]
    }
   ],
   "source": [
    "#Adding ~4000 features extracted from house_rules to datacleaned\n",
    "categorical_columns = data_cleaned.select_dtypes(include=['category']).columns\n",
    "data_cleaned=pd.concat([data_cleaned,extracted_features], axis=1)\n",
    "\n",
    "#Dropping redundant column 'translated' from the dataset\n",
    "data_cleaned.drop('translated',axis=1,inplace=True)\n",
    "print(data_cleaned.shape)\n",
    "\n",
    "\n",
    "# OneHotEncoding for Categorical Variables for Model Compatibility\n",
    "data_encoded = pd.get_dummies(data_cleaned, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a58d3f",
   "metadata": {},
   "source": [
    "##### Notes for Harshita\n",
    "\n",
    "- data_cleaned: Data with all features without encoding, and response (price). Can be used for EDA and Outlier Detection\n",
    "- data_encoded: OneHotEncoded data. Not meaningful for outlier detection, EDA, or feature selection. Purely for model inputs. This step needs to be done after EDA, outlier detection, and feature selection is completed.\n",
    "- I also removed useless features such as 'house_rules', 'country', 'country_code', 'lat', 'long' as country and country code for the entire dataset were United States. I removed lat and long as they are raw coordinates that have no significance without context. I removed house rules as it is pure paragraphical text data which we cannot process for a forecasting task. I removed service fee as it is already included in the price (100% correlation to response)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa52e4d0",
   "metadata": {},
   "source": [
    "### EDA - Harshita"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e5745d",
   "metadata": {},
   "source": [
    "## Notes for Krishna\n",
    "\n",
    "Correrlation matrix is taking forever to run, do you have any tricks to make it faster?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2a5ab9",
   "metadata": {},
   "source": [
    "#### Correlation between all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01bf7d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Correlation between all the quantitative variables\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "correlation_matrix=data_encoded.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7163634c",
   "metadata": {},
   "source": [
    "### Mutual Information between all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "729cfccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0021227726145554016\n"
     ]
    }
   ],
   "source": [
    "### Mutual Information between response variable and the rest of the features\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "columns=data_encoded.columns\n",
    "\n",
    "Mutual_Inforamtion=[]\n",
    "\n",
    "\n",
    "for column in columns:\n",
    "\n",
    "    mi=mutual_info_regression(data_encoded[[column]],response)\n",
    "    Mutual_Inforamtion.append(mi[0])\n",
    "    \n",
    "\n",
    "\n",
    "### Portion of the output(Can delete)\n",
    "print(Mutual_Inforamtion[1:5][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55474871",
   "metadata": {},
   "source": [
    "### PCA - Harshitha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b311952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of variance explained [0.0100249  0.00896012 0.00836197 0.00744095 0.00703767 0.00680054\n",
      " 0.00637863 0.00604605 0.00592185 0.00582162 0.00566516 0.0056394\n",
      " 0.00543532 0.00530089 0.00513925 0.0050467  0.00491914 0.00485636\n",
      " 0.00482317 0.00466772 0.00458317 0.00456163 0.00452406 0.00445315\n",
      " 0.00441909 0.00436705 0.00433595 0.00428937 0.00422588 0.00417551\n",
      " 0.00415646 0.00406292 0.00400388 0.00393735 0.00387918 0.00378026\n",
      " 0.00375405 0.00373553 0.00368651 0.00366972 0.00363523 0.00362026\n",
      " 0.00358275 0.00356836 0.00355191 0.00354484 0.00353287 0.00346552\n",
      " 0.00344564 0.00342808 0.00342431 0.00340341 0.00338604 0.00337188\n",
      " 0.00336049 0.00332193 0.00329401 0.00328821 0.00325153 0.0032277\n",
      " 0.00320274 0.00316892 0.00315412 0.00312781 0.00308713 0.00305936\n",
      " 0.00302684 0.0030173  0.0029764  0.00294556 0.00294144 0.0029012\n",
      " 0.00287861 0.00287493 0.00285556 0.00281602 0.00279411 0.0027757\n",
      " 0.00274838 0.00272034 0.00270155 0.00268771 0.00266977 0.00263926\n",
      " 0.00263319 0.00260835 0.00258162 0.00255134 0.00254383 0.00252015\n",
      " 0.00251445 0.00248788 0.00246968 0.00245936 0.00244137 0.00241725\n",
      " 0.00240329 0.00238227 0.00236689 0.00236491]\n",
      "Percentage of variance explained [9.96877678e-01 2.23078468e-03 5.85001131e-04 2.91576340e-04\n",
      " 6.44514674e-06 4.67333030e-06 3.70787779e-07 2.83733798e-07\n",
      " 2.47457634e-07 1.32246618e-07 8.56009961e-08 7.58311260e-08\n",
      " 7.00450406e-08 6.90086053e-08 5.64456479e-08 4.81739247e-08\n",
      " 4.70591859e-08 4.51456797e-08 4.33466433e-08 3.97771714e-08\n",
      " 3.69041905e-08 3.63865798e-08 3.56211995e-08 3.47125343e-08\n",
      " 3.37455655e-08 3.17855992e-08 2.98908280e-08 2.85087807e-08\n",
      " 2.81012252e-08 2.66953761e-08 2.59156640e-08 2.45733325e-08\n",
      " 2.28752205e-08 2.24509935e-08 2.10935915e-08 2.04790322e-08\n",
      " 2.03439932e-08 1.96490659e-08 1.91397285e-08 1.88155649e-08\n",
      " 1.82881279e-08 1.76417933e-08 1.73727458e-08 1.69970644e-08\n",
      " 1.63938540e-08 1.62704434e-08 1.59876461e-08 1.59266386e-08\n",
      " 1.55905997e-08 1.47573695e-08 1.45776927e-08 1.44354528e-08\n",
      " 1.42698341e-08 1.38404433e-08 1.33859368e-08 1.31232501e-08\n",
      " 1.28357805e-08 1.25442232e-08 1.21801014e-08 1.21100850e-08\n",
      " 1.19024779e-08 1.15998100e-08 1.14661218e-08 1.13021092e-08\n",
      " 1.11734098e-08 1.09323252e-08 1.08260121e-08 1.06633838e-08\n",
      " 1.05269044e-08 1.03191559e-08 1.02310033e-08 1.00651666e-08\n",
      " 9.91782616e-09 9.72370190e-09 9.51770513e-09 9.47844662e-09\n",
      " 9.29644176e-09 9.08687672e-09 8.99227287e-09 8.94688006e-09\n",
      " 8.62201266e-09 8.57125272e-09 8.44628266e-09 8.32974644e-09\n",
      " 8.14595290e-09 8.10785533e-09 7.98920399e-09 7.86221184e-09\n",
      " 7.79414274e-09 7.68460680e-09 7.54723306e-09 7.48250369e-09\n",
      " 7.37979686e-09 7.31583435e-09 7.22223902e-09 6.90990884e-09\n",
      " 6.86794250e-09 6.82939147e-09 6.79538321e-09 6.73130516e-09]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#Scaling the features\n",
    "scaler=StandardScaler()\n",
    "scaled_data=scaler.fit_transform(data_encoded)\n",
    "\n",
    "\n",
    "#PCA with Standardization\n",
    "pca_standardized=PCA(n_components=100)\n",
    "pca_components_standardized=pca_standardized.fit(scaled_data)\n",
    "print(\"Percentage of variance explained\",pca_standardized.explained_variance_ratio_)\n",
    "\n",
    "\n",
    "#PCA without standardization\n",
    "\n",
    "pca_unstandardized=PCA(n_components=100)\n",
    "pca_components_unstandardized= pca_unstandardized.fit(data_encoded)\n",
    "print(\"Percentage of variance explained\",pca_unstandardized.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a862295f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3851096555806529\n",
      "0.9999989682491139\n"
     ]
    }
   ],
   "source": [
    "#Sum of variance explained\n",
    "\n",
    "sum_unstandardized=sum(pca_standardized.explained_variance_ratio_)\n",
    "sum_standardized=sum(pca_unstandardized.explained_variance_ratio_)\n",
    "\n",
    "\n",
    "print(sum_unstandardized)\n",
    "print(sum_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18941184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10260, 4079)\n",
      "(10260,)\n"
     ]
    }
   ],
   "source": [
    "#Extracting the relevant features from PCA\n",
    "\n",
    "# Store Features in X\n",
    "X_PCA = pca_standardized.fit_transform(data_encoded)\n",
    "print(X.shape)\n",
    "# Store Response Variables in y\n",
    "y = response\n",
    "print(y.shape)\n",
    "\n",
    "# Train Test Split\n",
    "X_PCA_train, X_PCA_test, y_train, y_test = train_test_split(X_PCA, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcc7ce1",
   "metadata": {},
   "source": [
    "### Outlier Detection - Harshita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76c8acf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier detection with LocalOutlierFactor\n",
    "\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "lof=LocalOutlierFactor(n_neighbors=20)\n",
    "outliers_lof=lof.fit_predict(data_encoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9956571",
   "metadata": {},
   "source": [
    "Notes about adjustments needed:\n",
    "\n",
    "Randomly chose a value of 0.1 for contamination in isolation forest- need to figure out how to determine it.\n",
    "Also need to figure out how to deal with the outliers i.e. delete them or keep them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54ef6dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier detection with Isolation Forest\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "param={'contamination':[0.001,0.01,0.05,0.1,0.15],'n_estimators':[50,100,200,500],'max_samples':[0.5,0.7,1],'bootstrap':['True','False']}\n",
    "\n",
    "IsolationForest_model= IsolationForest(random_state=42)\n",
    "grid=GridSearchCV(IsolationForest_model,param,cv=5,scoring=silhouette_score_func)\n",
    "IsolationForest_model.fit(data_encoded)\n",
    "\n",
    "outliers_Isolaionforest=IsolationForest_model.predict(data_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93007c30",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "465397d0",
   "metadata": {},
   "source": [
    "### Train Test Split - Krishna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "619abd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoding for Categorical Variables for Model Compatibility\n",
    "#data_encoded = pd.get_dummies(data_cleaned, drop_first=True)\n",
    "\n",
    "# Store Features in X\n",
    "X = data_encoded\n",
    "\n",
    "#Scaling X\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#Scaling the features\n",
    "scaler=StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "\n",
    "# Store Response Variables in y\n",
    "y = response\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a5f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54842d5",
   "metadata": {},
   "source": [
    "### Feature Selection -Harshitha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2c2ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Lasso Regression to perform Feature Selection\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "model_lasso=LassoCV(cv=5, max_iter=10000).fit(X_train,y_train)\n",
    "model_lasso.mse_path_\n",
    "\n",
    "Optimal_lambda=  model_lasso.alpha_\n",
    "\n",
    "\n",
    "#Extracting selected features\n",
    "coefficients= model_lasso.coef_\n",
    "selected_features_indices= np.where(coefficients!=0)[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3ae75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features=data_encoded.columns[selected features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13692223",
   "metadata": {},
   "source": [
    "### Feature Selection - Krishna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03a24bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutual Information Initialization\n",
    "mi_scores = mutual_info_regression(X_train, y_train)\n",
    "mi_scores_series = pd.Series(mi_scores, index=X_train.columns)\n",
    "\n",
    "# Thresholds to test\n",
    "thresholds = [0.001, 0.005, 0.01]\n",
    "\n",
    "# Initialize variables to track the best thresholds and scores\n",
    "best_mi_t = 0\n",
    "best_mi_score = 0\n",
    "best_xgb_t = 0\n",
    "best_xgb_score = 0\n",
    "best_features_mi = []\n",
    "best_features_xgb = []\n",
    "\n",
    "# Loop through thresholds for both MI and XGBoost feature selection\n",
    "for t in thresholds:\n",
    "    print(f'Threshold: {t}')\n",
    "    print('-' * 30)\n",
    "    \n",
    "    # Mutual Information Feature Selection\n",
    "    mi_selected_features = mi_scores_series[mi_scores_series > t].index\n",
    "    X_train_mi = X_train[mi_selected_features]\n",
    "    print(f\"MI Features Selected: {len(mi_selected_features)}\")\n",
    "\n",
    "    # Evaluate using cross-validation after MI selection\n",
    "    mi_scores = cross_val_score(XGBRegressor(n_estimators=200,random_state=42), X_train_mi, y_train, cv=10, scoring='r2')\n",
    "    mi_mean_score = mi_scores.mean()\n",
    "\n",
    "    # Update best MI threshold and score and save features\n",
    "    if mi_mean_score > best_mi_score:\n",
    "        best_mi_score = mi_mean_score\n",
    "        best_mi_t = t\n",
    "        best_features_mi = mi_selected_features.tolist()\n",
    "\n",
    "    print(f\"MI Mean CV Score: {mi_mean_score:.4f}\")\n",
    "\n",
    "    # XGBoost Feature Importance Refinement\n",
    "    xgb_model = XGBRegressor(random_state=42)\n",
    "    xgb_model.fit(X_train_mi, y_train)\n",
    "    xgb_importances = pd.Series(xgb_model.feature_importances_, index=X_train_mi.columns)\n",
    "    print(\"delete, these are the importancea\", xgb_importances)\n",
    "\n",
    "    # Apply XGBoost threshold to further refine features\n",
    "    xgb_selected_features = xgb_importances[xgb_importances > t].index\n",
    "    X_train_xgb = X_train_mi[xgb_selected_features]\n",
    "    print(f\"XGBoost Features Selected: {len(xgb_selected_features)}\")\n",
    "\n",
    "    # Evaluate using cross-validation after XGBoost refinement\n",
    "    xgb_scores = cross_val_score(XGBRegressor(random_state=42), X_train_xgb, y_train, cv=5, scoring='r2')\n",
    "    xgb_mean_score = xgb_scores.mean()\n",
    "    print(\"delete, this is the score\",xgb_mean_score)\n",
    "    # Update best XGBoost threshold and score and save features\n",
    "    if xgb_mean_score > best_xgb_score:\n",
    "        best_xgb_score = xgb_mean_score\n",
    "        best_xgb_t = t\n",
    "        best_features_xgb = xgb_selected_features.tolist()\n",
    "\n",
    "\n",
    "    print(f\"XGBoost Mean CV Score: {xgb_mean_score:.4f}\")\n",
    "    print('-' * 30)\n",
    "\n",
    "# Final Results\n",
    "print(f\"Best MI Threshold: {best_mi_t}, Best MI Mean CV Score: {best_mi_score:.4f}\")\n",
    "print(f\"Best XGBoost Threshold: {best_xgb_t}, Best XGBoost Mean CV Score: {best_xgb_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2fd837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Best Features from Training and Test Sets\n",
    "X_train_final = X_train[best_features_xgb]\n",
    "X_test_final = X_test[best_features_xgb]\n",
    "\n",
    "print(\"\\nFeatures selected by Mutual Information and XGBoost:\\n\" + \"\\n\".join(best_features_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32800b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final.shape, X_test_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8454b257",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e35491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Harshitha delete\n",
    "\n",
    "print(data_encoded.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec76c980",
   "metadata": {},
   "source": [
    "## Linear Regression - Krishna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c65804",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b387da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harshitha's changes included\n",
    "\n",
    "X_train_final_const = sm.add_constant(X_train)\n",
    "X_test_final_const = sm.add_constant(X_test)\n",
    "\n",
    "#Extracting Boolean Columns\n",
    "\n",
    "boolean=X_train_final_const.select_dtypes(include=['bool']).columns\n",
    "X_train_final_const=X_train_final_const[boolean].astype(int)\n",
    "\n",
    "\n",
    "boolean=X_test_final_const.select_dtypes(include=['bool']).columns\n",
    "X_test_final_const=X_test_final_const[boolean].astype(int)\n",
    "\n",
    "\n",
    "ols_model = sm.OLS(y_train, X_train_final_const).fit()\n",
    "\n",
    "y_pred = ols_model.predict(X_test_final_const)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(ols_model.summary(),'\\n')\n",
    "print('='*25)\n",
    "print(\"Test Set Performance:\")\n",
    "print('='*25)\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R-squared: {ols_model.rsquared:.2f}\")\n",
    "print('='*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61982dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete-HT\n",
    "print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f6cd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final_const = sm.add_constant(X_train_final)\n",
    "X_test_final_const = sm.add_constant(X_test_final)\n",
    "\n",
    "\n",
    "ols_model = sm.OLS(y_train, X_train_final_const).fit()\n",
    "\n",
    "y_pred = ols_model.predict(X_test_final_const)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(ols_model.summary(),'\\n')\n",
    "print('='*25)\n",
    "print(\"Test Set Performance:\")\n",
    "print('='*25)\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R-squared: {ols_model.rsquared:.2f}\")\n",
    "print('='*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a03f75",
   "metadata": {},
   "source": [
    "## Random Forest - Krishna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4701ad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='r2',\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_final, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4025417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete Harshitha\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='r2',\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f267ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=grid_search.best_params_['n_estimators'],\n",
    "    random_state=42,\n",
    "    max_depth=grid_search.best_params_['max_depth'],\n",
    "    min_samples_split=grid_search.best_params_['min_samples_split'],\n",
    "    min_samples_leaf=grid_search.best_params_['min_samples_leaf']\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992057d5",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ec3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Random Forest Test Performance:\")\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R-squared: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f1161d",
   "metadata": {},
   "source": [
    "## XGBoost - Krishna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2e9e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'reg_lambda': [1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42),\n",
    "    param_grid=param_grid_xgb,\n",
    "    cv=3,\n",
    "    scoring='r2',\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters for XGBoost:\", grid_search_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b192abc3",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2debfd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "212bb90f",
   "metadata": {},
   "source": [
    "## Meta Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aebb073",
   "metadata": {},
   "source": [
    "Note: Code for Feedforward model needs to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7cd1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feed Forward Neural Network\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "#Scaling the data\n",
    "\n",
    "scaler=StandardScaler()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model=Sequential([layers.InputLayer(input_shape=(Xtrain.shape[1],)), layers.Dense(64,activation='relu'), layers.Dense(32,activation='relu'),layers.Dense(1)])\n",
    "\n",
    "#Comiling the model\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bb4b06",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2322006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6ac5d40",
   "metadata": {},
   "source": [
    "#Code References\n",
    "\n",
    "https://www.nltk.org/api/nltk.tokenize.punkt.html\n",
    "https://stackoverflow.com/questions/1801668/convert-a-list-with-strings-all-to-lowercase-or-uppercase\n",
    "https://stackoverflow.com/questions/55508303/how-to-write-a-list-of-list-into-excel-using-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
